{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## extract results functions\n",
    "\n",
    "def extract_results_from_log(file_path, dataset_name):\n",
    "    with open(file_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    if dataset_name == \"mme\":\n",
    "        r_idx = 0\n",
    "        perception_results = []\n",
    "        cognition_results = []\n",
    "        for line in lines:\n",
    "            if line.startswith(\"total score: \"):\n",
    "                score = line.replace(\"total score: \", \"\").strip()\n",
    "                score = float(score)\n",
    "                if r_idx % 2 == 0:\n",
    "                    perception_results.append(score)\n",
    "                else:\n",
    "                    cognition_results.append(score)\n",
    "                r_idx += 1\n",
    "        avg_percp = sum(perception_results) / len(perception_results)\n",
    "        avg_cogn = sum(cognition_results) / len(cognition_results)\n",
    "        \n",
    "        perception_results = [f\"{score:.2f}\" for score in perception_results]\n",
    "        cognition_results = [f\"{score:.2f}\" for score in cognition_results]\n",
    "        avg_percp = f\"{avg_percp:.2f}\"\n",
    "        avg_cogn = f\"{avg_cogn:.2f}\"\n",
    "        perc_string = \"+\".join(perception_results)\n",
    "        cogn_string = \"+\".join(cognition_results)\n",
    "        result_str = f\"({perc_string})/3={avg_percp}|({cogn_string})/3={avg_cogn}\"\n",
    "        return result_str\n",
    "\n",
    "    elif dataset_name == \"llava_bench\":\n",
    "        results = []\n",
    "        for line in lines:\n",
    "            if line.startswith(\"all \"):\n",
    "                score = line.split(\" \")[1]\n",
    "                score = float(score)\n",
    "                results.append(score)\n",
    "        avg = sum(results) / len(results)\n",
    "        results = [f\"{score:.2f}\" for score in results]\n",
    "        avg = f\"{avg:.2f}\"\n",
    "        score_str = \"+\".join(results)\n",
    "        result_str = f\"({score_str})/3={avg}\"\n",
    "        return result_str\n",
    "    \n",
    "    elif dataset_name == \"mmbench\":\n",
    "        return \"\"\n",
    "    \n",
    "    elif dataset_name == \"mmvet\":\n",
    "        return \"\"\n",
    "    \n",
    "    elif dataset_name == \"seed\":\n",
    "        for line in lines:\n",
    "            if line.startswith(\"image accuracy: \"):\n",
    "                score = line.replace(\"image accuracy: \", \"\").strip()\n",
    "                score = score.replace(\"%\", \"\")\n",
    "                score = float(score)\n",
    "                return score\n",
    "\n",
    "    elif dataset_name == \"gqa\":\n",
    "        for line in lines:\n",
    "            if line.startswith(\"Accuracy: \"):\n",
    "                score = line.replace(\"Accuracy: \", \"\").strip()\n",
    "                score = score.replace(\"%\", \"\")\n",
    "                score = float(score)\n",
    "                return score\n",
    "    elif dataset_name == \"sqa\":\n",
    "        # Total: 4241, Correct: 2970, Accuracy: 70.03%, IMG-Accuracy: 69.11%\n",
    "        for line in lines:\n",
    "            if line.startswith(\"Total: \"):\n",
    "                acc = line.split(\" Accuracy: \")[1]\n",
    "                acc = acc.split(\"%\")[0]\n",
    "                img_acc = line.split(\" IMG-Accuracy: \")[1]\n",
    "                img_acc = img_acc.split(\"%\")[0]\n",
    "                return f\"{acc}|{img_acc}\"\n",
    "    \n",
    "    elif dataset_name == \"pope\":\n",
    "        results = []\n",
    "        for line in lines:\n",
    "            if line.startswith(\"Accuracy: \"):\n",
    "                score = line.replace(\"Accuracy: \", \"\").strip()\n",
    "                score = float(score)\n",
    "                score = score * 100\n",
    "                results.append(f\"{score:.2f}\")\n",
    "        return \"|\".join(results)\n",
    "    \n",
    "    elif dataset_name == \"textvqa\":\n",
    "        for line in lines:\n",
    "            if line.startswith(\"Accuracy: \"):\n",
    "                score = line.replace(\"Accuracy: \", \"\").strip()\n",
    "                score = score.replace(\"%\", \"\")\n",
    "                score = float(score)\n",
    "                return score\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown dataset name: {dataset_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "first_line_datasets = [\n",
    "    \"mme\",\n",
    "    \"llava_bench\",\n",
    "    \"mmbench\",\n",
    "    \"mmvet\",\n",
    "    \"seed\"\n",
    "]\n",
    "second_line_datasets = [\n",
    "    \"gqa\",\n",
    "    \"sqa\",\n",
    "    \"textvqa\",\n",
    "    \"pope\"\n",
    "]\n",
    "\n",
    "\n",
    "## clip\n",
    "input_log_dirs = [\n",
    "    # \"/shared/nas2/wangz3/salesforce_intern_nas2/open_clip_merging/LLaVA/results/eval_logs/instance_level-72out__pretrained_openai__schedule-constant\",\n",
    "    # \"/shared/nas2/wangz3/salesforce_intern_nas2/open_clip_merging/LLaVA/results/eval_logs_repeat_token/rerun_new_repeat__instance_level-72out__pretrained_openai__schedule-constant\",\n",
    "    # \"/shared/nas2/wangz3/salesforce_intern_nas2/open_clip_merging/LLaVA/results/eval_logs_repeat_token/rerun_new_repeat__instance_level-192out__pretrained_openai__schedule-constant\",\n",
    "    # \"/shared/nas2/wangz3/salesforce_intern_nas2/open_clip_merging/LLaVA/results/eval_logs_repeat_token/clsbugfix_apply_thresh_to_pretrained-72out_no_repeat\",\n",
    "    \"/shared/nas2/wangz3/salesforce_intern_nas2/open_clip_merging/LLaVA/results/eval_logs_repeat_token/rerun_rerun_new_repeat__clsbugfix_apply_thresh_to_pretrained-72out_repeat\",\n",
    "    \"/shared/nas2/wangz3/salesforce_intern_nas2/open_clip_merging/LLaVA/results/eval_logs_repeat_token/rerun_rerun_new_repeat__clsbugfix_apply_thresh_to_pretrained-192out_repeat\",\n",
    "    \"/shared/nas2/wangz3/salesforce_intern_nas2/open_clip_merging/LLaVA/results/eval_logs_repeat_token/rerun_rerun_new_repeat__clsbugfix_apply_thresh_to_pretrained-384out_repeat\",\n",
    "    # \"/shared/nas2/wangz3/salesforce_intern_nas2/open_clip_merging/LLaVA/results/eval_logs_repeat_token/rerun_rerun_new_repeat__clsbugfix_apply_thresh_to_pretrained-480out_repeat\",\n",
    "    # \"/shared/nas2/wangz3/salesforce_intern_nas2/open_clip_merging/LLaVA/results/eval_logs_repeat_token/rerun_rerun_new_repeat__apply_thresh_to_pretrained-192out_repeat_schedule-linear\",\n",
    "    # \"/shared/nas2/wangz3/salesforce_intern_nas2/open_clip_merging/LLaVA/results/eval_logs_repeat_token/rerun_rerun_new_repeat__apply_thresh_to_pretrained-192out_repeat_schedule-rev-linear\",\n",
    "    # \"/shared/nas2/wangz3/salesforce_intern_nas2/open_clip_merging/LLaVA/results/eval_logs_repeat_token/rerun_rerun_new_repeat__clsbugfix_apply_thresh_to_pretrained-192out_repeat_pixmo\"\n",
    "]\n",
    "layer_idx = 22\n",
    "\n",
    "\n",
    "# ## siglip\n",
    "# input_log_dirs = [\n",
    "#     \"/shared/nas2/wangz3/salesforce_intern_nas2/open_clip_merging/LLaVA/results/eval_logs_repeat_token/rerun_no_repeat__siglip_instance_level-72out\",\n",
    "#     \"/shared/nas2/wangz3/salesforce_intern_nas2/open_clip_merging/LLaVA/results/eval_logs_repeat_token/rerun_new_repeat__siglip_instance_level-72out\",\n",
    "#     \"/shared/nas2/wangz3/salesforce_intern_nas2/open_clip_merging/LLaVA/results/eval_logs_repeat_token/rerun_rerun_new_repeat__siglip_apply_thresh_to_pretrained-72out_repeat\",\n",
    "#     \"/shared/nas2/wangz3/salesforce_intern_nas2/open_clip_merging/LLaVA/results/eval_logs_repeat_token/rerun_rerun_new_repeat__siglip_apply_thresh_to_pretrained-192out_repeat\",\n",
    "#     \"/shared/nas2/wangz3/salesforce_intern_nas2/open_clip_merging/LLaVA/results/eval_logs_repeat_token/rerun_rerun_new_repeat__siglip_apply_thresh_to_pretrained-384out_repeat\",\n",
    "#     \"/shared/nas2/wangz3/salesforce_intern_nas2/open_clip_merging/LLaVA/results/eval_logs_repeat_token/siglip_apply_thresh_to_pretrained-480out_repeat\"\n",
    "# ]\n",
    "# layer_idx = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results written to /shared/nas2/wangz3/salesforce_intern_nas2/open_clip_merging/LLaVA/results/summary_tsv_files/summary.tsv\n"
     ]
    }
   ],
   "source": [
    "## visualize results\n",
    "output_tsv_file = \"/shared/nas2/wangz3/salesforce_intern_nas2/open_clip_merging/LLaVA/results/summary_tsv_files/summary.tsv\"\n",
    "write_lines = []\n",
    "\n",
    "for input_log_dir in input_log_dirs:\n",
    "    write_lines.append(\"#######################\")\n",
    "    write_lines.append(\"Model: \" + input_log_dir.split(\"/\")[-1] + \"\\n\")\n",
    "\n",
    "    header_line = \"\"\n",
    "    results_line = \"\"\n",
    "    for dataset in first_line_datasets:\n",
    "        header_line += f\"{dataset}\\t\"\n",
    "        log_file_path = os.path.join(input_log_dir, f\"{dataset}.log\")\n",
    "        if os.path.exists(log_file_path):\n",
    "            result_str = extract_results_from_log(log_file_path, dataset)\n",
    "            results_line += f\"{result_str}\\t\"\n",
    "        else:\n",
    "            results_line += \"N/A\\t\"\n",
    "    write_lines.append(header_line)\n",
    "    write_lines.append(results_line+\"\\n\")\n",
    "\n",
    "    header_line = \"\"\n",
    "    results_line = \"\"\n",
    "    for dataset in second_line_datasets:\n",
    "        log_file_path = os.path.join(input_log_dir, f\"{dataset}.log\")\n",
    "        header_line += f\"{dataset}\\t\"\n",
    "        if os.path.exists(log_file_path):\n",
    "            result_str = extract_results_from_log(log_file_path, dataset)\n",
    "            results_line += f\"{result_str}\\t\"\n",
    "        else:\n",
    "            results_line += \"N/A\\t\"\n",
    "    write_lines.append(header_line)\n",
    "    write_lines.append(results_line)\n",
    "    write_lines.append(\"#######################\\n\")\n",
    "\n",
    "with open(output_tsv_file, 'w') as f:\n",
    "    f.writelines(\"\\n\".join(write_lines))\n",
    "print(f\"Results written to {output_tsv_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: rerun_rerun_new_repeat__clsbugfix_apply_thresh_to_pretrained-72out_repeat | Stats for all datasets:\n",
      "max: 195.11\n",
      "min: 20.33\n",
      "avg: 89.44\n",
      "med: 88.11\n",
      "std: 27.33\n",
      "Model: rerun_rerun_new_repeat__clsbugfix_apply_thresh_to_pretrained-192out_repeat | Stats for all datasets:\n",
      "max: 353.22\n",
      "min: 61.33\n",
      "avg: 194.77\n",
      "med: 194.00\n",
      "std: 47.42\n",
      "Model: rerun_rerun_new_repeat__clsbugfix_apply_thresh_to_pretrained-384out_repeat | Stats for all datasets:\n",
      "max: 536.89\n",
      "min: 199.22\n",
      "avg: 393.63\n",
      "med: 395.56\n",
      "std: 57.49\n",
      "Results written to /shared/nas2/wangz3/salesforce_intern_nas2/open_clip_merging/LLaVA/results/summary_tsv_files/summary_ntok.tsv\n"
     ]
    }
   ],
   "source": [
    "# Visualize tok number\n",
    "import json\n",
    "from collections import defaultdict\n",
    "def show_ntok_stats_from_jsonl(input_ans_jsonl, layer_idx):\n",
    "    with open(input_ans_jsonl, \"r\") as f:\n",
    "        answers = [json.loads(line) for line in f]\n",
    "    ntoks_all_instance = []\n",
    "    for ans in answers:\n",
    "        if ans[\"metadata\"][\"ntok_instance\"] is None:\n",
    "            continue\n",
    "        ntoks_all_instance.append(ans[\"metadata\"][\"ntok_instance\"][f\"block_{layer_idx}_ntoks\"])\n",
    "    \n",
    "    ntok_max =  max(ntoks_all_instance)\n",
    "    ntok_min = min(ntoks_all_instance)\n",
    "    ntok_avg = sum(ntoks_all_instance) / len(ntoks_all_instance)\n",
    "    ntok_med = sorted(ntoks_all_instance)[len(ntoks_all_instance) // 2]\n",
    "    ntok_std = (sum([(ntok - ntok_avg) ** 2 for ntok in ntoks_all_instance]) / len(ntoks_all_instance)) ** 0.5\n",
    "\n",
    "    # stat_str = f\"Max:{ntok_max}, Min:{ntok_min}, Avg:{ntok_avg:.2f}, Med:{ntok_med}, Std:{ntok_std:.2f}\"\n",
    "    stat_str = f\"{ntok_max}|{ntok_min}|{ntok_avg:.1f}|{ntok_med}|{ntok_std:.1f}\"\n",
    "    return stat_str, {\"max\": ntok_max, \"min\": ntok_min, \"avg\": ntok_avg, \"med\": ntok_med, \"std\": ntok_std}\n",
    "\n",
    "def find_jsonl(dataset_name, model_name, eval_root=\"/shared/nas2/wangz3/salesforce_intern_nas2/llava_1_5_data/eval\"):\n",
    "    if dataset_name == \"mme\":\n",
    "        p = os.path.join(eval_root, \"MME\", \"answers\", f\"{model_name}.jsonl\")\n",
    "        if not os.path.exists(p):\n",
    "            p = os.path.join(eval_root, \"MME\", \"answers\", f\"{model_name}_1.jsonl\")\n",
    "    elif dataset_name == \"llava_bench\":\n",
    "        p = os.path.join(eval_root, \"llava-bench-in-the-wild\", \"answers\", f\"{model_name}.jsonl\")\n",
    "        if not os.path.exists(p):\n",
    "            p = os.path.join(eval_root, \"llava-bench-in-the-wild\", \"answers\", f\"{model_name}_1.jsonl\")\n",
    "    elif dataset_name == \"mmbench\":\n",
    "        p = os.path.join(eval_root, \"mmbench/answers/mmbench_dev_20230712\", f\"{model_name}.jsonl\")\n",
    "    elif dataset_name == \"mmvet\":\n",
    "        p = os.path.join(eval_root, \"mm-vet/answers\", f\"{model_name}.jsonl\")\n",
    "    elif dataset_name == \"seed\":\n",
    "        p = os.path.join(eval_root, \"seed_bench/answers\", f\"{model_name}\", \"merge.jsonl\")\n",
    "    elif dataset_name == \"gqa\":\n",
    "        p = os.path.join(eval_root, \"gqa/answers/llava_gqa_testdev_balanced\", f\"{model_name}\", \"merge.jsonl\")\n",
    "    elif dataset_name == \"sqa\":\n",
    "        p = os.path.join(eval_root, \"scienceqa/answers\", f\"{model_name}.jsonl\")\n",
    "    elif dataset_name == \"pope\":\n",
    "        p = os.path.join(eval_root, \"pope/answers\", f\"{model_name}.jsonl\")\n",
    "    elif dataset_name == \"textvqa\":\n",
    "        p = os.path.join(eval_root, \"textvqa/answers\", f\"{model_name}.jsonl\")\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown dataset name: {dataset_name}\")\n",
    "    return p\n",
    "\n",
    "output_tsv_file_ntok = \"/shared/nas2/wangz3/salesforce_intern_nas2/open_clip_merging/LLaVA/results/summary_tsv_files/summary_ntok.tsv\"\n",
    "\n",
    "write_lines = []\n",
    "\n",
    "\n",
    "for input_log_dir in input_log_dirs:\n",
    "    model_name = input_log_dir.split(\"/\")[-1]\n",
    "    write_lines.append(\"#######################\")\n",
    "    write_lines.append(\"Model: \" + model_name + \"\\n\")\n",
    "    stats_all_datasets = defaultdict(list)\n",
    "\n",
    "    header_line = \"\"\n",
    "    results_line = \"\"\n",
    "    for dataset in first_line_datasets:\n",
    "        header_line += f\"{dataset}\\t\"\n",
    "        log_file_path = os.path.join(input_log_dir, f\"{dataset}.log\")\n",
    "        if os.path.exists(log_file_path):\n",
    "            jsonl_path = find_jsonl(dataset, model_name)\n",
    "            result_str, info = show_ntok_stats_from_jsonl(jsonl_path, layer_idx)\n",
    "            results_line += f\"{result_str}\\t\\t\"\n",
    "            for k, v in info.items():\n",
    "                stats_all_datasets[k].append(v)\n",
    "        else:\n",
    "            results_line += \"N/A\\t\\t\"\n",
    "    write_lines.append(header_line)\n",
    "    write_lines.append(results_line+\"\\n\")\n",
    "\n",
    "    header_line = \"\"\n",
    "    results_line = \"\"\n",
    "    for dataset in second_line_datasets:\n",
    "        log_file_path = os.path.join(input_log_dir, f\"{dataset}.log\")\n",
    "        header_line += f\"{dataset}\\t\"\n",
    "        if os.path.exists(log_file_path):\n",
    "            jsonl_path = find_jsonl(dataset, model_name)\n",
    "            result_str, info = show_ntok_stats_from_jsonl(jsonl_path, layer_idx)\n",
    "            results_line += f\"{result_str}\\t\\t\"\n",
    "            for k, v in info.items():\n",
    "                stats_all_datasets[k].append(v)\n",
    "        else:\n",
    "            results_line += \"N/A\\t\\t\"\n",
    "    write_lines.append(header_line)\n",
    "    write_lines.append(results_line)\n",
    "    write_lines.append(\"#######################\\n\")\n",
    "\n",
    "    # show avg stats all datasets #\n",
    "    print(f\"Model: {model_name} | Stats for all datasets:\")\n",
    "    for k, v in stats_all_datasets.items():\n",
    "        avg = sum(v) / len(v)\n",
    "        print(f\"{k}: {avg:.2f}\")\n",
    "\n",
    "with open(output_tsv_file_ntok, 'w') as f:\n",
    "    f.writelines(\"\\n\".join(write_lines))\n",
    "print(f\"Results written to {output_tsv_file_ntok}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original_llava: 64.10\n",
      "ours-72out: 62.38\n",
      "ours-192out: 63.49\n",
      "ours-324out: 64.21\n"
     ]
    }
   ],
   "source": [
    "# compute ntok avg stats\n",
    "\n",
    "performance = {\n",
    "    \"original_llava\": sum([75.3, 63.5, 64.6, 30.7, 66.2, 62.0, 69.41, 58.27, (88.2+87.3+85.2)/3]) / 9,\n",
    "    \"ours-72out\": sum([71.9, 62.9, 62.1, 30, 65.0, 60.8, 69.3, 53.1, (87.5+86.8+84.6)/3]) / 9,\n",
    "    \"ours-192out\": sum([74.1, 65.1, 62.8, 30.9, 65.9, 61.7, 69.2, 55.1, (87.9+87.0+84.9)/3]) / 9,\n",
    "    \"ours-324out\": sum([74.9, 64.5, 64.3, 31.5, 66.1, 61.9, 69.9, 58.0, (88.1+87.2+85.2)/3 ]) / 9\n",
    "}\n",
    "\n",
    "# avg, std\n",
    "ntok = {\n",
    "    \"original_llava\": [576, 0],\n",
    "    \"ours-72out\": [89.4, 27.3],\n",
    "    \"ours-192out\": [194.8, 47.4],\n",
    "    \"ours-384out\": [393.6, 57.5]\n",
    "}\n",
    "\n",
    "# plot"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llava",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
